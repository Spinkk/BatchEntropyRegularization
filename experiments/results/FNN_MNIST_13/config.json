{"N_LAYERS": 500, "WIDTH": 128, "ACTIVATIONS": "relu", "LBE_STRENGTH": 3.0, "LBE_ALPHA": 1.5, "LBE_ALPHA_MIN": 0.3, "INITIALIZER": "glorot_uniform", "BATCH_SIZE": 512, "LEARNING_RATE": 0.0001, "patience": 10, "ADAM_BETA1": 0.95, "ADAM_EPSILON": 1e-07, "GLOBAL_CLIPNORM": 1.0}